{
  "metadata": {
    "kernelspec": {
      "name": "xpython",
      "display_name": "Python 3.13 (XPython)",
      "language": "python"
    },
    "language_info": {
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "version": "3.13.1"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "cf6542ba-3cb7-4770-b02a-f27ff5f6d3ba",
      "cell_type": "markdown",
      "source": "### WRITE A PROGRAM TO FIND OUT THE FREQUENCIES OF DISTINCT WORDS, GIVEN A SENTENCE USING N-GRAMS.",
      "metadata": {}
    },
    {
      "id": "f8b99b3c-e856-4698-b573-3a3e4a749f63",
      "cell_type": "code",
      "source": "from collections import Counter\n\ndef generate_ngrams(sentence, n):\n    words = sentence.split()\n    ngrams = [tuple(words[i:i+n]) for i in range(len(words)-n+1)]\n    return Counter(ngrams)\n\ndef print_ngrams(sentence, max_n=3):\n    for n in range(1, max_n+1):\n        freq = generate_ngrams(sentence, n)\n        print(f\"\\n{n}-grams:\")\n        for gram, count in freq.items():\n            # Join tuple into a string for cleaner display\n            gram_str = \" \".join(gram)\n            print(f\"  {gram_str:<30} → {count}\")\n\n# Example usage\nsentence = \"I love Python and I love programming in Python\"\nprint_ngrams(sentence, max_n=4)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n1-grams:\n  I                              → 2\n  love                           → 2\n  Python                         → 2\n  and                            → 1\n  programming                    → 1\n  in                             → 1\n\n2-grams:\n  I love                         → 2\n  love Python                    → 1\n  Python and                     → 1\n  and I                          → 1\n  love programming               → 1\n  programming in                 → 1\n  in Python                      → 1\n\n3-grams:\n  I love Python                  → 1\n  love Python and                → 1\n  Python and I                   → 1\n  and I love                     → 1\n  I love programming             → 1\n  love programming in            → 1\n  programming in Python          → 1\n\n4-grams:\n  I love Python and              → 1\n  love Python and I              → 1\n  Python and I love              → 1\n  and I love programming         → 1\n  I love programming in          → 1\n  love programming in Python     → 1\n"
        }
      ],
      "execution_count": 8
    },
    {
      "id": "ecf52b25-d4bf-4fee-8646-9cc7c5525013",
      "cell_type": "markdown",
      "source": "### ADDITIONAL PROGRAMS: Program to Calculate Probabilities of Each N‑gram",
      "metadata": {}
    },
    {
      "id": "015a1ae2-a143-4558-9c30-e9a9d2b284ca",
      "cell_type": "code",
      "source": "from collections import Counter\n\ndef generate_ngrams(sentence, n):\n    words = sentence.split()\n    ngrams = [tuple(words[i:i+n]) for i in range(len(words)-n+1)]\n    return ngrams\n\ndef ngram_probabilities(sentence, n):\n    ngrams = generate_ngrams(sentence, n)\n    total = len(ngrams)\n    freq = Counter(ngrams)\n    probs = {gram: count/total for gram, count in freq.items()}\n    return probs\n\ndef print_all_ngram_probabilities(sentence, max_n=3):\n    for n in range(1, max_n+1):\n        print(f\"\\n{n}-gram Probabilities:\")\n        probs = ngram_probabilities(sentence, n)\n        for gram, prob in probs.items():\n            gram_str = \" \".join(gram)\n            print(f\"  {gram_str:<30} → {prob:.3f}\")\n\n# Example usage\nsentence = \"I am Ayush Kumar Singh\"\nprint_all_ngram_probabilities(sentence, max_n=4)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n1-gram Probabilities:\n  I                              → 0.200\n  am                             → 0.200\n  Ayush                          → 0.200\n  Kumar                          → 0.200\n  Singh                          → 0.200\n\n2-gram Probabilities:\n  I am                           → 0.250\n  am Ayush                       → 0.250\n  Ayush Kumar                    → 0.250\n  Kumar Singh                    → 0.250\n\n3-gram Probabilities:\n  I am Ayush                     → 0.333\n  am Ayush Kumar                 → 0.333\n  Ayush Kumar Singh              → 0.333\n\n4-gram Probabilities:\n  I am Ayush Kumar               → 0.500\n  am Ayush Kumar Singh           → 0.500\n"
        }
      ],
      "execution_count": 3
    },
    {
      "id": "1491f28f-e08f-48ae-b757-b25d98287dfc",
      "cell_type": "markdown",
      "source": "### ADDITIONAL PROGRAMS: Program to Generate N‑grams in Reverse Order",
      "metadata": {}
    },
    {
      "id": "c5abf327-a37f-426a-bd7e-f88ffda9636e",
      "cell_type": "code",
      "source": "def generate_reverse_ngrams(sentence, n):\n    words = sentence.split()\n    ngrams = [tuple(words[i-n+1:i+1]) for i in range(n-1, len(words))]\n    ngrams.reverse()  # reverse the order\n    return ngrams\n\n# Example usage\nsentence = \"I am Ayush Kumar\"\nprint(\"Reverse Trigrams:\")\nfor gram in generate_reverse_ngrams(sentence, 3):\n    print(\" \".join(gram))",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Reverse Trigrams:\nam Ayush Kumar\nI am Ayush\n"
        }
      ],
      "execution_count": 4
    },
    {
      "id": "9ddd25a2-8918-4780-9c77-57fca7e5d147",
      "cell_type": "markdown",
      "source": "## ADDITIONAL PROG(dont write): WAP that builds a bi gram language model from a givencorpus and computes the perplexipity of a given test sentence using the bigram probabilities",
      "metadata": {}
    },
    {
      "id": "22dcbea8-d0e4-430b-8779-cc590a9ed011",
      "cell_type": "code",
      "source": "from collections import Counter\nimport math\n\ndef build_bigram_model(corpus):\n    words = corpus.split()\n    vocab = set(words)\n    V = len(vocab)\n\n    unigram_counts = Counter(words)\n    bigram_counts = Counter((words[i], words[i+1]) for i in range(len(words)-1))\n\n    return unigram_counts, bigram_counts, V\n\ndef bigram_probability(w1, w2, unigram_counts, bigram_counts, V):\n    return (bigram_counts[(w1, w2)] + 1) / (unigram_counts[w1] + V)\n\ndef sentence_probability(sentence, unigram_counts, bigram_counts, V):\n    words = sentence.split()\n    prob = 1.0\n    for i in range(len(words)-1):\n        prob *= bigram_probability(words[i], words[i+1], unigram_counts, bigram_counts, V)\n    return prob\n\ndef perplexity(sentence, unigram_counts, bigram_counts, V):\n    words = sentence.split()\n    prob = sentence_probability(sentence, unigram_counts, bigram_counts, V)\n    return prob ** (-1/len(words))\n\n# Example usage\ncorpus = \"i love python i love programming in python\"\ntest_sentence = \"i love python\"\n\nunigram_counts, bigram_counts, V = build_bigram_model(corpus)\npp = perplexity(test_sentence, unigram_counts, bigram_counts, V)\n\nprint(\"Perplexity of test sentence:\", pp)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Perplexity of test sentence: 2.013793539326758\n"
        }
      ],
      "execution_count": 5
    },
    {
      "id": "1ca2b627-b32f-4ffc-9ef5-1573bb628050",
      "cell_type": "markdown",
      "source": "## Python program that implements an N‑gram backoff language model. It uses trigrams when available, backs off to bigrams if unseen, and finally falls back to unigrams when both are unavailable. Laplace smoothing is applied at each level to avoid zero probabilities.\n",
      "metadata": {}
    },
    {
      "id": "d03288a4-c490-41a7-a221-8a32b2159dd5",
      "cell_type": "code",
      "source": "from collections import Counter\nimport math\n\ndef build_ngram_model(corpus):\n    words = corpus.split()\n    vocab = set(words)\n    V = len(vocab)\n\n    unigram_counts = Counter(words)\n    bigram_counts = Counter((words[i], words[i+1]) for i in range(len(words)-1))\n    trigram_counts = Counter((words[i], words[i+1], words[i+2]) for i in range(len(words)-2))\n\n    return unigram_counts, bigram_counts, trigram_counts, V\n\ndef backoff_probability(w1, w2, w3, unigram_counts, bigram_counts, trigram_counts, V):\n    # Try trigram\n    if trigram_counts[(w1, w2, w3)] > 0:\n        prob = (trigram_counts[(w1, w2, w3)] + 1) / (bigram_counts[(w1, w2)] + V)\n        source = \"Trigram\"\n    # Backoff to bigram\n    elif bigram_counts[(w2, w3)] > 0:\n        prob = (bigram_counts[(w2, w3)] + 1) / (unigram_counts[w2] + V)\n        source = \"Bigram\"\n    # Backoff to unigram\n    else:\n        prob = (unigram_counts[w3] + 1) / (sum(unigram_counts.values()) + V)\n        source = \"Unigram\"\n    return prob, source\n\ndef sentence_probability(sentence, unigram_counts, bigram_counts, trigram_counts, V):\n    words = sentence.split()\n    prob = 1.0\n    print(\"\\nWord Probabilities with Backoff:\")\n    for i in range(2, len(words)):\n        p, source = backoff_probability(words[i-2], words[i-1], words[i],\n                                        unigram_counts, bigram_counts, trigram_counts, V)\n        print(f\"P({words[i]} | {words[i-2]} {words[i-1]}) = {p:.4f}  [{source}]\")\n        prob *= p\n    return prob\n\ndef perplexity(sentence, unigram_counts, bigram_counts, trigram_counts, V):\n    words = sentence.split()\n    prob = sentence_probability(sentence, unigram_counts, bigram_counts, trigram_counts, V)\n    return prob ** (-1/len(words))\n\n# Example usage\ncorpus = \"i love python i love programming in python python is great and i love it\"\ntest_sentence = \"i love python is great\"\n\nunigram_counts, bigram_counts, trigram_counts, V = build_ngram_model(corpus)\npp = perplexity(test_sentence, unigram_counts, bigram_counts, trigram_counts, V)\n\nprint(\"\\nPerplexity of test sentence:\", pp)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\nWord Probabilities with Backoff:\nP(python | i love) = 0.1667  [Trigram]\nP(is | love python) = 0.1667  [Bigram]\nP(great | python is) = 0.2000  [Trigram]\n\nPerplexity of test sentence: 2.825234500494767\n"
        }
      ],
      "execution_count": 7
    },
    {
      "id": "a1d0fbcc-97ce-4b85-ae60-c0dade198b28",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}